import os
from playwright.async_api import Page

# ğŸ” FUNCÈšIE PRINCIPALÄ‚ pentru a apela subcategoriile
async def scrape_category_details(page: Page, category_url: str, results_folder: str):
    print(f"[ğŸ“¥] Scraping category page: {category_url}")

    # ğŸ‘‰ ApelÄƒm funcÈ›ia care parcurge subcategoriile È™i salveazÄƒ textul
    await browse_subcategories_and_save_text(page, category_url, results_folder)

# ğŸ” FUNCÈšIE pentru a parcurge subcategoriile È™i a salva conÈ›inutul
import os
from playwright.async_api import Page

async def browse_subcategories_and_save_text(page: Page, category_url: str, results_folder: str):
    print(f"[ğŸ“‚] Searching subcategories in: {category_url}")

    try:
        await page.wait_for_selector('button[data-test="sub-waste-type-card-button"]', timeout=8000)
        buttons = await page.query_selector_all('button[data-test="sub-waste-type-card-button"]')
    except:
        print("[âš ï¸] No subcategories found.")
        return

    print(f"[ğŸ“„] Found {len(buttons)} subcategories.")

    for i, button in enumerate(buttons):
        href = await button.get_attribute("onclick")
        if not href or "window.location.href" not in href:
            print(f"[âŒ] Could not extract subcategory URL from button {i+1}")
            continue

        sub_url_path = href.split("'")[1]
        sub_url = f"https://www.clearago.de{sub_url_path}"

        new_page = await page.context.new_page()
        print(f"[â¡ï¸] Opening subcategory: {sub_url}")
        await new_page.goto(sub_url)

        # ÃncearcÄƒ sÄƒ gÄƒseÈ™ti È™i sÄƒ apeÈ™i butonul 'Mehr...' Ã®n maxim 3 secunde
        try:
            mehr_button = await new_page.wait_for_selector('div[data-test="rolling-container-more"]', timeout=3000)
            await mehr_button.click()
            print("[ğŸŸ¢] Clicked 'Mehr...' button to expand.")
            await new_page.wait_for_timeout(1000)  # aÈ™teaptÄƒ puÈ›in dupÄƒ click
        except:
            print("[âš ï¸] 'Mehr...' button not found or not clickable. Continuing.")
        

        # SalveazÄƒ tot conÈ›inutul text
        try:
            body_text = await new_page.inner_text('body')
        except:
            body_text = "[âŒ] Failed to read page content."

        url_part = sub_url.replace("https://www.clearago.de/", "").replace("/", "-").strip("-")
        filename = os.path.join(results_folder, f"{url_part}.txt")
        os.makedirs(results_folder, exist_ok=True)

        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"[URL]: {sub_url}\n\n")
            f.write(body_text)

        print(f"[ğŸ’¾] Saved content to {filename}")
        await new_page.close()

